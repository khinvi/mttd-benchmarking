# MTTD Benchmarking Framework

A standardized methodology for measuring and comparing Mean Time to Detect (MTTD) across different commercial cloud security services.

## Overview

The MTTD Benchmarking Framework provides organizations with a repeatable, objective way to evaluate the detection capabilities of cloud security services. The framework simulates realistic attack scenarios using the MITRE ATT&CK framework, monitors security services for alerts, and calculates metrics like MTTD, detection rates, and false positive rates.

## Key Features

- **Standardized Testing**: Consistent methodology for comparing security services
- **Realistic Attack Simulation**: Based on MITRE ATT&CK framework and real-world attack patterns
- **Multi-Cloud Support**: Works with AWS, Azure, and GCP security services
- **Comprehensive Metrics**: Measures MTTD, detection rates, false positives, and alert distribution
- **Detailed Reporting**: Generates comparative reports and visualizations
- **Extensible Architecture**: Easy to add new security services and attack techniques

## Architecture

The framework consists of six core modules:

1. **Threat Simulation Engine**: Executes attack scenarios across cloud platforms
2. **Detection Monitoring System**: Collects security events from various services
3. **Metric Collection & Analysis**: Processes event data to calculate MTTD and other metrics
4. **Reporting & Visualization**: Generates reports and visual comparisons
5. **Test Scenario Manager**: Orchestrates test execution and manages environments
6. **Service Integration Layer**: Provides standardized interfaces to various security services

## Installation

### Prerequisites

- Python 3.9+
- Access to cloud platform accounts (AWS, Azure, and/or GCP)
- Cloud security services to test (GuardDuty, Security Hub, Sentinel, etc.)
- Required Python packages (see requirements.txt)

### Setup

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/mttd-benchmarking.git
   cd mttd-benchmarking
   ```

2. Install required packages:
   ```
   pip install -r requirements.txt
   ```

3. Configure cloud credentials:
   - For AWS, configure credentials using AWS CLI or environment variables
   - For Azure, set up authentication using az CLI or environment variables
   - For GCP, set up authentication using gcloud CLI or service account keys

4. Update the configuration file:
   ```
   cp config/config.example.json config/config.json
   ```
   Edit `config.json` with your cloud environment details and preferences.

## Usage

### Command Line Interface

The framework provides a command-line interface for running tests and generating reports:

#### List Available Scenarios

```
python -m src.cli list
```

#### Execute a Single Scenario

```
python -m src.cli execute --scenario-id aws-privilege-escalation-001
```

#### Run a Benchmark Across Multiple Services

```
python -m src.cli benchmark --scenarios aws-privilege-escalation-001,aws-data-exfiltration-001 --services aws_guardduty,aws_securityhub,third_party_service_1
```

### Web Interface

The framework also provides a web-based UI for easier interaction:

1. Start the web server:
   ```
   python -m src.web_ui.app
   ```

2. Access the interface at `http://localhost:5000`

## Creating Custom Scenarios

Custom attack scenarios can be created by defining JSON scenario files in the `config/scenarios` directory. Each scenario must include:

- **Platform details**: Which cloud platform and region to use
- **Environment configuration**: Resources to create for the test
- **Attack steps**: Sequence of MITRE ATT&CK techniques to execute
- **Expected alerts**: Alerts that should be generated by security services

Example scenario structure:

```json
{
  "id": "custom-scenario-001",
  "name": "Custom Attack Scenario",
  "description": "Description of the scenario",
  "platform": {
    "name": "aws",
    "service_name": "aws_guardduty",
    "region": "us-west-2"
  },
  "environment_config": {
    "resources": {
      "ec2_instance": [{ "instance_type": "t2.micro" }]
    }
  },
  "steps": [
    {
      "name": "First Step",
      "technique_id": "T1078",
      "parameters": { "user_name": "test-user" },
      "expected_indicators": ["aws-api-call"]
    }
  ],
  "expected_alerts": [
    {
      "service": "aws_guardduty",
      "finding_type": "UnauthorizedAccess:IAMUser/MaliciousIPCaller",
      "severity": "MEDIUM",
      "time_to_detect_range": [60, 300]
    }
  ]
}
```

## Adding New Security Services

The framework can be extended to support additional security services by:

1. Creating a new client implementation in the `src/service_integration` directory
2. Updating the service factory to include the new service
3. Adding the service configuration to `config.json`

## Reports and Metrics

The framework generates several types of reports:

- **JSON reports**: Detailed metrics and benchmark data
- **CSV reports**: Tabular data for import into spreadsheets
- **Visualization data**: For rendering charts and graphs

Key metrics include:

- **Mean Time to Detect (MTTD)**: Average time between attack execution and detection
- **Detection Rate**: Percentage of attack indicators that were detected
- **False Positive Rate**: Proportion of alerts that didn't correspond to actual attacks
- **Severity Distribution**: Breakdown of alerts by severity level

## Research Applications

This framework enables several important cybersecurity research directions:

1. Establishing empirical baselines for MTTD across different providers
2. Identifying detection blind spots in cloud security services
3. Analyzing the relationship between alert volume and accuracy
4. Measuring how MTTD varies across different attack techniques
5. Evaluating the impact of security service configuration on detection capabilities

## Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues to improve the framework.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Security Considerations

This framework simulates attack techniques for benchmarking purposes only. Always:

- Use dedicated test environments, never production
- Obtain proper authorization before testing
- Follow responsible disclosure processes if vulnerabilities are discovered
- Ensure all testing complies with applicable laws and regulations

## Acknowledgments

- MITRE ATT&CKÂ® framework
- Cloud security service providers
- Security researchers who have developed similar methodologies